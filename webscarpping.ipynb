{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleanning and web scrapping for upcoming moveis from TMDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the useful library\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "response = requests.get(\"https://www.themoviedb.org/movie\", headers = needed_headers )\n",
    "page_contents = response.text\n",
    "page_contents[:500]\n",
    "doc= BeautifulSoup(page_contents, 'html.parser')\n",
    "response.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the movie pages using request\n",
    "#remember to create a personal API so that we can using the request\n",
    "def get_movies_page(movies_url):\n",
    "    \"\"\"\n",
    "    Function to download a web page using `requests` and check the status code to validate\n",
    "    if the call was successful. \n",
    "    \"\"\"\n",
    "    # Access the webpage using `requests`\n",
    "    needed_headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "    response = requests.get(movies_url, headers = needed_headers )\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(movies_url))\n",
    "    # Parse the `response' text using BeautifulSoup\n",
    "    movies_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return movies_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movies links for those movies and save it from scrapping the further info:\n",
    "def get_url(movies_names_tags):\n",
    "    links = []\n",
    "    for movie_links in movies_names_tags:\n",
    "        links.append(movie_links.a['href'])\n",
    "    print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lr/3wzrzz7j0gg0gs1x88x7xslm0000gn/T/ipykernel_917/3089339376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmovie_scrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/lr/3wzrzz7j0gg0gs1x88x7xslm0000gn/T/ipykernel_917/3089339376.py\u001b[0m in \u001b[0;36mmovie_scrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmovies_url_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_movies_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmovies_names_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_url_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#Exclude the first 4 lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_names_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovies_names_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# get 20 pages movies url and info:\n",
    "def movie_scrap():\n",
    "    movies_url_list = [] # store the url in dictionary that we can perform furhter operations\n",
    "    movies_names = []\n",
    "    for i in range(1,10):\n",
    "        movies_url = \"https://www.themoviedb.org/movie?page=%d\" %(i)\n",
    "        movies_url_list.append(get_movies_page(movies_url))\n",
    "    \n",
    "    movies_names_tags = movies_url_list.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "    url = get_url(movies_names_tags)\n",
    "    for h2 in movies_names_tags:\n",
    "        names.append(h2.a.text.strip())\n",
    "    return url\n",
    "\n",
    "movie_scrap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black Adam', 'R.I.P.D. 2: Rise of the Damned', 'Paradise City', 'Hex', 'Disenchanted', 'Black Panther: Wakanda Forever', 'Emily the Criminal', 'Lost Bullet 2', 'Sniper: The White Raven', 'Medieval', 'On the Line', 'Smile', 'Frank and Penelope', 'Margaux', 'Corrective Measures', 'The Soccer Football Movie', \"Tom and Jerry Snowman's Land\", 'Slumberland', 'Enola Holmes 2', 'The Woman King']\n"
     ]
    }
   ],
   "source": [
    "# we would like to get moveis name from the h2 content:\n",
    "movies_names_tags = doc.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "names = []\n",
    "for h2 in movies_names_tags:\n",
    "    names.append(h2.a.text.strip())\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancate the movie and the movie url:\n",
    "def get_movies_names(doc):\n",
    "    \"\"\"\n",
    "    Function to extract the movie names from HTML source code using BeautifulSoup.\n",
    "    \"\"\"\n",
    "    movies_names_tags = doc.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "    movies_names = []\n",
    "    # Loop through the page get all the movie names from the page\n",
    "    for h2 in movies_names_tags:\n",
    "        movies_names.append(h2.a.text.strip())\n",
    "    return movies_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_link = \"https://www.themoviedb.org/tv\"\n",
    "\n",
    "# 'i' here means the number of page we want to extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black Adam',\n",
       " 'R.I.P.D. 2: Rise of the Damned',\n",
       " 'Paradise City',\n",
       " 'Hex',\n",
       " 'Disenchanted',\n",
       " 'Black Panther: Wakanda Forever',\n",
       " 'Emily the Criminal',\n",
       " 'Lost Bullet 2',\n",
       " 'Sniper: The White Raven',\n",
       " 'Medieval',\n",
       " 'On the Line',\n",
       " 'Smile',\n",
       " 'Frank and Penelope',\n",
       " 'Margaux',\n",
       " 'Corrective Measures',\n",
       " 'The Soccer Football Movie',\n",
       " \"Tom and Jerry Snowman's Land\",\n",
       " 'Slumberland',\n",
       " 'Enola Holmes 2',\n",
       " 'The Woman King']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movies_names(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_urls(doc):\n",
    "    \"\"\"\n",
    "    Function to extract the movie links from HTML source code using BeautifulSoup. \n",
    "    \"\"\"\n",
    "    movies_urls = []\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    movies_names_tags = doc.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "    # Loop through the webpage to get the URL of each movie\n",
    "    for tag in movies_names_tags:\n",
    "        movies_urls.append(base_url + tag.a['href'])\n",
    "    return movies_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.themoviedb.org/movie/436270',\n",
       " 'https://www.themoviedb.org/movie/1013860',\n",
       " 'https://www.themoviedb.org/movie/829799',\n",
       " 'https://www.themoviedb.org/movie/988233',\n",
       " 'https://www.themoviedb.org/movie/338958',\n",
       " 'https://www.themoviedb.org/movie/505642',\n",
       " 'https://www.themoviedb.org/movie/862965',\n",
       " 'https://www.themoviedb.org/movie/948276',\n",
       " 'https://www.themoviedb.org/movie/966220',\n",
       " 'https://www.themoviedb.org/movie/551271',\n",
       " 'https://www.themoviedb.org/movie/979924',\n",
       " 'https://www.themoviedb.org/movie/882598',\n",
       " 'https://www.themoviedb.org/movie/899294',\n",
       " 'https://www.themoviedb.org/movie/846778',\n",
       " 'https://www.themoviedb.org/movie/872177',\n",
       " 'https://www.themoviedb.org/movie/1037858',\n",
       " 'https://www.themoviedb.org/movie/1018403',\n",
       " 'https://www.themoviedb.org/movie/668461',\n",
       " 'https://www.themoviedb.org/movie/829280',\n",
       " 'https://www.themoviedb.org/movie/724495']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movies_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_movie_page(movies_url):\n",
    "    \"\"\"\n",
    "    Function to read the HTML source code using BeautifulSoup.\n",
    "    \"\"\"\n",
    "    # Download the page\n",
    "    response = requests.get(movies_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(movies_url))\n",
    "    # Parse using Beautiful soup\n",
    "    movies_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return movies_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "doc1 = get_movies_page('https://www.themoviedb.org/movie/436270')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/21/2022 ['Action,', 'Fantasy,', 'Science', 'Fiction'] ['2h', '5m']\n"
     ]
    }
   ],
   "source": [
    "# Find the `div` tag under `facts` class to get the release date, genre and runtime \n",
    "div_tags = doc1.find('div', class_ = 'facts')\n",
    "\n",
    "release_date = div_tags.text.split()[1]\n",
    "genre = div_tags.text.split()[3:-2]\n",
    "runtime = div_tags.text.split()[-2:]\n",
    "\n",
    "# Print and validate the result is correct\n",
    "print(release_date, genre, runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dwayne Johnson\n"
     ]
    }
   ],
   "source": [
    "d_tags = doc1.find_all('div', {'class':'scroller_wrap should_fade is_fading'})\n",
    "\n",
    "# Print and validate the result\n",
    "print (d_tags[0].text.strip().partition(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_info(doc):\n",
    "    \"\"\"\n",
    "    Function to get the movie informations - \n",
    "    release date, genre, runtime and director.\n",
    "    \"\"\"\n",
    "    div1_tags = doc.find('div', class_ = 'facts')\n",
    "    release_date = div1_tags.text.split()[1]\n",
    "    genre = div1_tags.text.split()[3:-2]\n",
    "    runtime = div1_tags.text.split()[-2:]\n",
    "    \n",
    "    div2_tags = doc.find_all('div', {'class':'scroller_wrap should_fade is_fading'})\n",
    "    director = div2_tags[0].text.strip().partition(\"\\n\")[0]\n",
    "    \n",
    "    return release_date, genre, runtime, director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('10/21/2022',\n",
       " ['Action,', 'Fantasy,', 'Science', 'Fiction'],\n",
       " ['2h', '5m'],\n",
       " 'Dwayne Johnson')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movies_info(doc1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's start new here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's start new here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_page(tmdb_url):\n",
    "\n",
    "    needed_headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "    response = requests.get(tmdb_url, headers = needed_headers )\n",
    "    # Access the webpage using `requests`\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(tmdb_url))\n",
    "    # Parse the `response' text using BeautifulSoup\n",
    "    movies_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return movies_doc\n",
    "\n",
    "#get_movies_page(\"https://www.themoviedb.org/movie?page=%d\" %(i))\n",
    "doc = get_movies_page(\"https://www.themoviedb.org/movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black Adam',\n",
       " 'R.I.P.D. 2: Rise of the Damned',\n",
       " 'Paradise City',\n",
       " 'Hex',\n",
       " 'Disenchanted',\n",
       " 'Black Panther: Wakanda Forever',\n",
       " 'Emily the Criminal',\n",
       " 'Lost Bullet 2',\n",
       " 'Sniper: The White Raven',\n",
       " 'Medieval',\n",
       " 'On the Line',\n",
       " 'Smile',\n",
       " 'Frank and Penelope',\n",
       " 'Margaux',\n",
       " 'Corrective Measures',\n",
       " 'The Soccer Football Movie',\n",
       " \"Tom and Jerry Snowman's Land\",\n",
       " 'Slumberland',\n",
       " 'Enola Holmes 2',\n",
       " 'The Woman King']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_movies_names(doc):\n",
    "    \"\"\"\n",
    "    Function to extract the movie names from HTML source code using BeautifulSoup.\n",
    "    \"\"\"\n",
    "    movies_names_tags = doc.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "    movies_names = []\n",
    "    # Loop through the page get all the movie names from the page\n",
    "    for h2 in movies_names_tags:\n",
    "        movies_names.append(h2.a.text.strip())\n",
    "    return movies_names\n",
    "get_movies_names(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['73.0',\n",
       " '68.0',\n",
       " '53.0',\n",
       " '38.0',\n",
       " '74.0',\n",
       " '75.0',\n",
       " '69.0',\n",
       " '68.0',\n",
       " '74.0',\n",
       " '72.0',\n",
       " '65.0',\n",
       " '68.0',\n",
       " '75.0',\n",
       " '68.0',\n",
       " '49.0',\n",
       " '70',\n",
       " '80',\n",
       " '80',\n",
       " '77.0',\n",
       " '78.0']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_movies_rating(doc):\n",
    "    \"\"\"\n",
    "    Function to extract the movie user rating from HTML source code using the BeautifulSoup. \n",
    "    \"\"\"\n",
    "    desc_selector = 'user_score_chart'\n",
    "    movies_rating_tags = doc.find_all('div', {'class': desc_selector})\n",
    "    movies_rating = []\n",
    "    # Loop through the webpage to get the ratings of all the movies in the page\n",
    "    for tag in movies_rating_tags:\n",
    "        movies_rating.append(tag.attrs['data-percent'])\n",
    "    return movies_rating\n",
    "get_movies_rating(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_urls(doc):\n",
    "    \"\"\"\n",
    "    Function to extract the movie links from HTML source code using BeautifulSoup. \n",
    "    \"\"\"\n",
    "    movies_urls = []\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    movies_names_tags = doc.find_all('h2')[4:]  #Exclude the first 4 lines\n",
    "    # Loop through the webpage to get the URL of each movie\n",
    "    for tag in movies_names_tags:\n",
    "        movies_urls.append(base_url + tag.a['href'])\n",
    "    return movies_urls\n",
    "movies_url = get_movies_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_movie_page(movies_url):\n",
    "    \"\"\"\n",
    "    Function to read the HTML source code using BeautifulSoup.\n",
    "    \"\"\"\n",
    "\n",
    "    movies_doc = get_movies_page(movies_url)\n",
    "    return movies_doc\n",
    "doc1 =get_detailed_movie_page(movies_url[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11/15/2022',\n",
       " ['Fantasy,', 'Action,', 'Comedy,', 'Crime'],\n",
       " ['1h', '42m'],\n",
       " 'Jeffrey Donovan')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_movies_info(doc):\n",
    "    \"\"\"\n",
    "    Function to get the movie informations - \n",
    "    release date, genre, runtime and director.\n",
    "    \"\"\"\n",
    "    div1_tags = doc.find('div', class_ = 'facts')\n",
    "    release_date = div1_tags.text.split()[1]\n",
    "    genre = div1_tags.text.split()[3:-2]\n",
    "    runtime = div1_tags.text.split()[-2:]\n",
    "    \n",
    "    div2_tags = doc.find_all('div', {'class':'scroller_wrap should_fade is_fading'})\n",
    "    director = div2_tags[0].text.strip().partition(\"\\n\")[0]\n",
    "    \n",
    "    return release_date, genre, runtime, director\n",
    "get_movies_info(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_movies_details(urls):\n",
    "    \"\"\"\n",
    "    Function to get lists of movie information as lists from all the pages. \n",
    "    \"\"\"\n",
    "    genres = []\n",
    "    release_dates = []\n",
    "    runtimes = []\n",
    "    directors = []\n",
    "    \n",
    "    # Loop through all the urls of the the movies \n",
    "    for url in urls:\n",
    "        movie_doc = get_movies_page(url)\n",
    "        # get_movies_info returns release_date, genre, runtime, director.\n",
    "        release_date, genre, runtime, director = get_movies_info(movie_doc)\n",
    "        # Convert the genre list to string on ` `. \n",
    "        genres.append(\" \".join(genre))\n",
    "        release_dates.append(release_date)\n",
    "        runtimes.append(\" \".join(runtime))\n",
    "        directors.append(director)\n",
    "        \n",
    "    return genres, release_dates, runtimes, directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_movies_details(movies_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
